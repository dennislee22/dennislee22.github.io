---
layout: default
title: Nvidia GPU Dashboard
parent: Machine Learning
nav_order: 8
---

# Nvidia GPU Dashboard
{: .no_toc }

Sometimes, one might wondering why the system takes long time to train a model using GPU. One of the possible reasons is the precious GPU card is not fully utilized to its maximum capability due to the script/code. Question is how does one know if the GPU card is firing its cylinders to its full potential? Let's do an experiment using Cloudera Machine Learning (CML) on Kubernetes platform powered by Openshift 4.8. CML is embedded with `workbench` and `Jupyterlab` notebook IDE for data scientist to do coding, EDA, etc. Let's use `Jupyterlab` notebook to explore the performance output, e.g. whether the code is fully/under utilizing the allocated GPU resource.

In this case, [Jupyterlab-nvdashboard](https://github.com/rapidsai/jupyterlab-nvdashboard) is to be installed to give an overview of the GPU utilization.


- TOC
{:toc}

---
## TBA
    

---